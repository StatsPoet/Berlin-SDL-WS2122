---
title: "QA and Meetings"
author: "asp20boost"
date: "15 Januar 2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown## Ergebnisse QA 17.01.21

Erklärbarkeit -> Generalisiertbarkei des Models auf dem neuen Datensatzt nicht zentral. 

Data Preparation zentral

.jpeg Suffix könnte ein Problem für den Scraper sein. 


## Model

```{r}
median("lange der Reviews")
log("preis") # fuer Lin Reg, not for Random Forests. 
```

Consider Feature Selection algorithms. Consider their relevance and needed work. 

> Aussage  ueber Appendix verpasst! was war da?

## Data Augmentation:
do we need to consider this?
-> skepsis, dass es fuer die Regression hilt. 


- Boostrapping. 

> Letzte Frage von Joel Verpasst -> er antwortete mit Ja. 




## Schreiben. 

bedenke, wer die Adressaten sind. 
nur Darstellung von speziellen Modellen noetig. 
i.e. xgboost ist kein speziellen Modell

### ZITTIEREN ALLES was es geht. ZITTIEREN IS life!






## Ergebisse Anton Treffen: Stichworter ohne Zuordnung (Vielleicht sagen die dir was Tobi)
- Sentiment analysis - Text nicht nehmen müssen
- Alles miteinbeziehen in 1 NN = Model schlecht. 
   1. Werte Strukturierter. 
   2. Objekt detektieren. 
- PCR

- Bilderscrapping
- Multilevel Set
- Image Regression
- Mittel CNN
   4. Fit testing 
   10. Komplizität = Overfitting. 

> Mixed Data Multiimput CNN

- Nicht gut erklärbar. 
- B0ossting 
- GBT2

## Notizen für die QnA vom 15.11

-   Ein wichtiger Teil ist Daten einlesen
-   Minimum 3000 Beobachtungen verwenden
-   Histogramme plotten und Korrelationen berrechnen als Einstieg für Paper
-   In der QnA wirkte es als wäre es gut wenn wir noch mehr Bilder aus dem Internet scrapen
-   Bilder und comments analysieren wären gut
-   Alle daten typen zusammen zu bringen ist die Stärke von neuronalen Netzen also sollten wir das machen
-   Interpretierbarkeit der Ergebnisse soll möglich sein. Also keine reine Blackbox. 
Stichwort statistisches lernen

-   Bis zur nächsten Session sollen wir mindestens die Daten runterladen und am besten die Bilder scrapen.
-   Bilder sollen in reduzierter Pixelanzahl (64x64 oder so) runtergeladen werden
-   Es gibt eine letzte Stadt mit der wir dann unsere Modelle gegeneinander antreten lassen
-   Modelle sollen so geschrieben werden dass es sie auf die neue Stadt angepasst werden kann